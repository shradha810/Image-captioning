{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35649,"status":"ok","timestamp":1619161938905,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"-xWdr74uzzvY","outputId":"bcc2c8bb-0790-4567-c123-326723a0ec11"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6369,"status":"ok","timestamp":1619161969528,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"ty8sl8JHoXXv","outputId":"f3bd09f4-838f-4384-a9c8-e69a617f9f8a"},"outputs":[],"source":["!pip install nltk==3.4.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7056,"status":"ok","timestamp":1619161991622,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"v5QrkzA6Jdwb","outputId":"ec222f5d-5de7-4582-965c-4ab8b43da8b7"},"outputs":[],"source":["import os\n","import numpy as np\n","import joblib\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","from torch.nn.utils.rnn import pack_padded_sequence\n","\n","import torch\n","import torchvision\n","from torchvision.transforms import ToTensor, Normalize, Compose, Resize\n","from PIL import Image\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sklearn.model_selection import train_test_split\n","from matplotlib.pyplot import imshow\n","import matplotlib.pyplot as plt\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.translate.meteor_score import meteor_score\n","import nltk.translate.bleu_score\n","from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6582,"status":"ok","timestamp":1619162613034,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"S-BcgkZRPVlf","outputId":"d91705ae-d1b2-4779-c938-1f71933a5171"},"outputs":[],"source":["training_data_images_path= '/content/drive/MyDrive/Deep Learning/A4/Data/Train/Images'\n","training_data_images_captions= joblib.load('/content/drive/MyDrive/Deep Learning/A4/Data/Train/train_captions.pkl')\n","training_data_images_captions = {k: training_data_images_captions[k] for k in list(training_data_images_captions)[:3000]}\n","\n","val_data_images_path= '/content/drive/MyDrive/Deep Learning/A4/Data/Val/Images'\n","val_data_images_captions= joblib.load('/content/drive/MyDrive/Deep Learning/A4/Data/Val/val_captions.pkl')\n","# val_data_images_captions = {k:val_data_images_captions[k] for k in list(val_data_images_captions)[:64]}\n","\n","\n","def generate_vocabulary(data):\n","\n","    vocabulary=[]\n","    for _,caption_list in data.items():\n","        for caption in caption_list:\n","\n","            if caption[0]==\"\\\"\":\n","                caption=caption[1:]\n","            if caption[-1]==\"\\\"\":\n","                caption=caption[:-1]\n","\n","            vocab=nltk.word_tokenize(caption)\n","            # print(vocab)\n","            vocabulary+=vocab\n","\n","    vocabulary=list(set(vocabulary))\n","    vocabulary2=['<start>','<end>','<pad>','<unk>']\n","    vocabulary=vocabulary2+vocabulary\n","\n","    vocab_dict={}\n","    cnt=0\n","    for word in vocabulary:\n","        vocab_dict[word]=cnt\n","        cnt+=1\n","    # print(vocab_dict)         \n","    return vocab_dict\n","\n","def pre_process_captions(data,vocab_dict):\n","    caption_in_no_list=[]\n","    max_length=0\n","    caption_max = 'hello'\n","\n","    for img_ids,caption_list in data.items():\n","       caption_no_list=[] \n","       for caption in caption_list:\n","\n","           if caption[0]==\"\\\"\":\n","               caption=caption[1:]\n","           if caption[-1]==\"\\\"\":\n","               caption=caption[:-1]\n","\n","           words=nltk.word_tokenize(caption)\n","\n","           if (len(words)>max_length):\n","             max_length = len(words)\n","             caption_max = caption\n","\n","           no_list=[vocab_dict['<start>']]\n","           for word in words:\n","               if word in vocab_dict.keys():\n","                 no=vocab_dict[word]\n","               else:\n","                 no=vocab_dict['<unk>']\n","      \n","               no_list.append(no)\n","           no_list.append(vocab_dict['<end>'])\n","           \n","           caption_no_list.append(no_list)\n","       caption_in_no_list.append(caption_no_list)\n","\n","    max_length+=2   \n","    print(\"max length\",max_length)\n","    print(caption_max)\n","    # for img_no in range(len(caption_in_no_list)):\n","    # count=0\n","    for five_captions in range(len(caption_in_no_list)):\n","      # count = count+1\n","      # print(count)\n","      # count1= 0\n","      for each_caption in range(len(caption_in_no_list[five_captions])):\n","        # count1 +=1\n","        # print(\"count1\",count1)\n","        # print(caption_in_no_list[img_no][five_captions])\n","        num_pad= max_length - len(caption_in_no_list[five_captions][each_caption])\n","        # print(\"num_pad\",num_pad)\n","        # num_count=0\n","        for i in range(num_pad):\n","          # num_count +=1\n","          # print(\"num_count\",num_count)\n","          caption_in_no_list[five_captions][each_caption].append(vocab_dict['<pad>'])\n","          \n","    \n","    return torch.FloatTensor(caption_in_no_list),max_length\n","\n","def caption_sentence_torch(data,max_length):\n","    caption_sentence_list=[]\n","\n","    for img_ids,caption_list in data.items():\n","       caption_lists=[] \n","       for caption in caption_list:\n","           if caption[0]==\"\\\"\":\n","               caption=caption[1:]\n","           if caption[-1]==\"\\\"\":\n","               caption=caption[:-1]\n","\n","           caption='<start> '+caption+' <end>'\n","           len_of_this_current_caption=len(caption.split(' '))\n","           no_pad_reqd=max_length-len_of_this_current_caption\n","\n","           pad_str=' <pad>'*no_pad_reqd\n","        #    print(no_pad_reqd)\n","           caption=caption+pad_str\n","           caption_lists.append(caption)\n","\n","       caption_sentence_list.append(caption_lists) \n","\n","    return caption_sentence_list\n","    \n","vocab_dict= generate_vocabulary(training_data_images_captions)\n","# joblib.dump(vocab_dict,'/content/drive/MyDrive/Deep Learning/A4/models/vocab_dict')\n","\n","train_caption_in_no_tensor,max_length= pre_process_captions(training_data_images_captions,vocab_dict)\n","# train_caption_sentences_list=caption_sentence_torch(training_data_images_captions,max_length)\n","\n","val_caption_in_no_tensor,max_length_val= pre_process_captions(val_data_images_captions,vocab_dict)\n","# val_caption_sentences_list=caption_sentence_torch(val_data_images_captions,max_length_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8622,"status":"ok","timestamp":1618761419492,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"zwQVDvcQrnRQ","outputId":"3ff25da7-166c-4fe2-a0b6-89d7386c38ec"},"outputs":[],"source":["print(train_caption_in_no_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7741,"status":"ok","timestamp":1618761419493,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"1WuVJFxDtOS2","outputId":"8a726521-39e1-4c8f-c1bf-bcb19e77fdcf"},"outputs":[],"source":["print(val_caption_in_no_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1188,"status":"ok","timestamp":1619163000824,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"md1jrH5N1pEm"},"outputs":[],"source":["# print(len(training_data_images_captions))\n","\n","# Size of x_train= (6000, H, W)  but resize them first while uploading and prprocessing\n","# Size of y_train= (6000, 5 )\n","\n","                   #########  DONT RUN UNLESS NEEDED ####  (takes time)\n","\n","def pre_process_and_load(image_path,captions):\n","    images_list=os.listdir(image_path)\n","\n","    x_train=[]\n","    y_train=[]\n","    cnt=0\n","    for image_id,caption_list in captions.items():\n","        # if (cnt>10):\n","        #     break\n","        # print(\" image Id ==> \",image_id ,\"\\ncaption_list===> \",caption_list)\n","\n","        print(cnt)\n","        if(image_id in images_list):\n","            # print(\"hello image is present\")\n","            img_path_to_read=image_path+ '/' +image_id\n","            img= cv2.imread(img_path_to_read)\n","            img=cv2.resize(img,(224,224))\n","            # cv2_imshow(img)\n","\n","            img=img/255.         \n","            img=img.astype('float32')\n","            img=torch.tensor(img).permute((2,0,1))\n","            x_train.append(img)\n","            y_train.append(caption_list)\n","\n","        cnt+=1\n","    return x_train,y_train\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8N_tQHgnbtw"},"outputs":[],"source":["\n","    \n","\n","x_train, y_train=  pre_process_and_load(training_data_images_path,training_data_images_captions)  \n","# x_train is list of tensor images\n","#y_train is list of list of list of str\n","x_val  ,y_val=   pre_process_and_load(val_data_images_path,val_data_images_captions)  \n","\n","\n","\n","x_train_tensor= torch.stack(x_train)\n","y_train=y_train\n","# x_train_tensor is tensor of tensor images\n","x_val_tensor= torch.stack(x_val)\n","y_val=y_val\n","\n","###################################################\n","# train_ds = list(zip(x_train_tensor,y_train))\n","# val_ds = list(zip(x_val_tensor,y_val))\n","###################################################\n","\n","train_ds = list(zip(x_train_tensor,train_caption_in_no_tensor))\n","val_ds = list(zip(x_val_tensor,val_caption_in_no_tensor))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1357,"status":"ok","timestamp":1619162910177,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"j7Qs_9cDLDeq"},"outputs":[],"source":["#################### shifting my training and val data to GPU  ###########################\n","#check whether cuda is available\n","def to_device(data, device):\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","    \n","class DeviceDataLoader():\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","    def __iter__(self):\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","    def __len__(self):\n","        return len(self.dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGBxKMP8b5Ih"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","batch_size = 32\n","train_dataset = DataLoader(train_ds, batch_size,shuffle=True)\n","val_dataset = DataLoader(val_ds,batch_size)\n","\n","train_dataset = DeviceDataLoader(train_dataset,torch.device('cuda'))  \n","val_dataset = DeviceDataLoader(val_dataset,torch.device('cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9eo9_dG0T5_"},"outputs":[],"source":["def save_model(model,file_name):\n","  pass\n","#   torch.save(model.state_dict(),'/content/drive/My Drive/Deep Learning/A4/models/'+file_name+'_cp.pth')\n","    \n","def load_model(file_name):\n","  return torch.load('/content/drive/My Drive/Deep Learning/A4/models/'+file_name+'_cp.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1054,"status":"ok","timestamp":1619162508446,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"uTqRV9EKfVzO"},"outputs":[],"source":["from torchvision.models import vgg19\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, network='vgg19'):\n","        super(Encoder, self).__init__()\n","        self.network = network\n","        self.net = vgg19(pretrained=True)\n","        self.net = nn.Sequential(*list(self.net.features.children())[:-1])\n","        self.dim = 512\n","\n","    def forward(self, x):\n","        # print(\"x==>\",x)\n","        x= self.net(x)\n","        # print(x)\n","        # print(x.shape)\n","\n","        x = x.permute(0, 2, 3, 1)\n","        # print(x.shape)\n","        x = x.view(x.size(0), -1, x.size(-1))\n","        # print(\"x shape\",x.shape)\n","        return x\n","\n","\n","# test_img=x_train_tensor[0].reshape(1,3,227,227)\n","# model1= Encoder()\n","# img_features=model1(test_img)\n","# print(img_features.shape)\n","# # print(model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1402,"status":"ok","timestamp":1619162504041,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"QJbz0tseg5lA"},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, encoder_dim):\n","        super(Attention, self).__init__()\n","        self.U = nn.Linear(512, 512)   #DECODER \n","        self.W = nn.Linear(encoder_dim, 512)  # ENCODER \n","        self.tanh = nn.Tanh()\n","\n","        self.v = nn.Linear(512, 1)\n","        self.softmax = nn.Softmax(1)\n","\n","    def forward(self, img_features, hidden_state):  # image features is the 196 hidden rep.   # hidden state is the last pixels hidden rep. OR So\n","        # print(\"img_feature\",img_features.shape)\n","        # print(\"hidden_state\",hidden_state.shape)\n","        # U_h = self.U(hidden_state).unsqueeze(1)  # hidden state of decoder basically 'S'\n","        # print(U_h.shape)\n","        \n","        U_h = self.U(hidden_state).unsqueeze(1)\n","        # print(\"u\",U_h.shape)\n","\n","        \n","        W_s = self.W(img_features)    #Encoder\n","        # print(W_s.shape)\n","\n","        att =self.tanh(W_s + U_h)\n","        e = self.v(att).squeeze(2)\n","\n","        # print(\"e \",e.shape)\n","\n","        alpha = self.softmax(e)\n","        # print(\"alpha sum:\",torch.sum(alpha))\n","        # print(\"alpha shape\",alpha.shape)\n","        # print(\"alpha shape unsqueeze(2) \",alpha.unsqueeze(2).shape)\n","        # print(img_features.shape)\n","        context = (img_features * alpha.unsqueeze(2)).sum(1)\n","        # print(context.shape)\n","        return context, alpha\n","\n","\n","# model2=Attention(512)\n","# ans0,ans1= model2(img_features,img_features[0:1,195,:])\n","# print(\"context :\",ans0.shape)\n","# print(\"alpha :\",ans1.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1147,"status":"ok","timestamp":1619162499901,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"XR-37zTVyozc"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, vocabulary_size, encoder_dim):#, tf=False):\n","\n","        super(Decoder, self).__init__()\n","        # self.use_tf = tf\n","\n","        self.vocabulary_size = vocabulary_size\n","        self.encoder_dim = encoder_dim\n","\n","        self.init_h = nn.Linear(encoder_dim, 512)\n","        self.init_c = nn.Linear(encoder_dim, 512)\n","        self.tanh = nn.Tanh()\n","\n","        self.f_beta = nn.Linear(512, encoder_dim)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.deep_output = nn.Linear(512, vocabulary_size)\n","        self.dropout = nn.Dropout(p=0.2)\n","\n","        self.attention = Attention(encoder_dim)\n","        self.embedding = nn.Embedding(vocabulary_size, 512)\n","        self.lstm = nn.LSTMCell(512 + encoder_dim, 512)\n","        self.softmax = nn.Softmax()\n","\n","    def forward(self, img_features, captions,max_len, flag=True):\n","\n","        # print(\"caption shape\", captions.shape)\n","        # print(\"image features shape===>\",img_features.shape)\n","        batch_size = img_features.size(0)\n","\n","        h, c = self.get_init_lstm_state(img_features)\n","        max_timespan =max_len # max([len(caption) for caption in captions]) - 1\n","        # print(\"max_timespan===>\",max_timespan)\n","\n","        prev_words = torch.zeros(batch_size, 1).long().cuda()\n","        # print(\"prev_words ka shape\",prev_words.shape)\n","        embedding = self.embedding(prev_words)\n","        # print(\"Embedding ==>\",embedding.shape)\n","\n","\n","        # print(\"batch size ==>\",batch_size)\n","        preds = torch.zeros(batch_size, max_timespan, self.vocabulary_size).cuda()\n","        alphas = torch.zeros(batch_size, max_timespan, img_features.size(1)).cuda()\n","\n","        \n","\n","        # test=captions[:,1,:1]\n","        # print(\"test type\",test.type())\n","        # print(\"prev words type\",prev_words.type())\n","        # print(\"test type\",test.shape)\n","        # print(\"prev words type\",prev_words.shape)\n","\n","        embedding = self.embedding(captions[:,0,0:1].long()) if flag==True else self.embedding(prev_words)\n","\n","        # embedding = self.embedding(captions[:,1,:1].long()) if flag==True else self.embedding(prev_words)\n","        # print(\"embedding-->\",embedding)\n","        # print(\"embedding shape-->\",embedding.shape)\n","        \n","        for t in range(max_timespan):\n","            # print(\"t==>\",t)\n","            context, alpha = self.attention(img_features, h)\n","            gate = self.sigmoid(self.f_beta(h))\n","            gated_context = gate * context\n","\n","            # gated_context=context #i added\n","\n","            # if(self.training and t!=0):\n","            #     use  TF\n","\n","            if (t!=0):# and self.training == True):\n","                # print(\"hi1\")                    \n","                # print(preds[:,t-1])   #179 values ka list (softmax)\n","                # print(\"hi   \",preds[:,t-1].shape) # 32,179\n","                maximum_index_in_pred=torch.argmax(preds[:,t-1,:], dim=1)   #(32 size ka ek list)\n","                # maximum_index_in_pred=maximum_index_in_pred.tolist()\n","                \n","                # print(\"hi2\")\n","                # maximum_index_in_pred=np.array(maximum_index_in_pred)\n","                maximum_index_in_pred=maximum_index_in_pred.reshape(maximum_index_in_pred.shape[0],1)\n","                # print(\"maximum_index_in_pred  =>\",maximum_index_in_pred)\n","\n","                # print(\"hi3\")\n","                # embedding= self.embedding(maximum_index_in_pred)\n","\n","\n","                embedding = self.embedding(captions[:,0,t-1:t].long()) if flag==True else self.embedding(maximum_index_in_pred)\n","                # print(\"embedding ka shape\", embedding.shape)\n","\n","                # print(\"hi4\")\n","\n","            # print(\"embedding shape \",embedding.shape)\n","            embedding=embedding.reshape(embedding.shape[0],embedding.shape[2])\n","            # print(\"e \",embedding.shape)\n","\n","\n","            lstm_input = torch.cat((embedding, gated_context), dim=1)\n","\n","\n","            h, c = self.lstm(lstm_input, (h, c))\n","            output1 = self.deep_output(self.dropout(h))\n","            # output = self.softmax(output1)\n","            # print(\"output train,\",output.shape)   #  batch size , vocab size  =(32 , 674 )\n","\n","            preds[:, t] = output1     # (32, 26, 179)\n","            alphas[:, t] = alpha\n","\n","            # if flag==False:\n","            #   embedding = self.embedding(output.max(1)[1].reshape(batch_size, 1))\n","\n","\n","            # if not self.training :\n","            #     print(output.max(1)[1])\n","            #     embedding = self.embedding(output.max(1)[1].reshape(batch_size, 1))\n","\n","        # print(\"preds decoder\",preds.shape)\n","        # print(\"alphas decoder\",alphas.shape)\n","        return preds, alphas\n","\n","    def get_init_lstm_state(self, img_features):\n","        # print(\"img_features shape decoder\",img_features.shape)\n","        avg_features = img_features.mean(dim=1) #img_features: 1,196,512\n","        # print(\"avg_features.shape\",avg_features.shape) #avg_features.shape: 1,512\n","\n","        c = self.init_c(avg_features)\n","        c = self.tanh(c)\n","\n","        h = self.init_h(avg_features)\n","        # print(\"h.shape\",h.shape)\n","        h = self.tanh(h)\n","\n","        return h, c\n","\n","# model3 = Decoder(len(vocab_dict),512)\n","# # print(y_train[0])\n","# preds, alphas = model3(img_features,y_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1172,"status":"ok","timestamp":1619162935492,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"GCDoxs8RkTB3"},"outputs":[],"source":["# from torch.nn.utils.rnn import pack_padded_sequence\n","\"\"\"\n","def calc_loss(pred_for_29_timestamps,targets_for_29_timestamps,max_len):  #(10,29)   (10,29)\n","\n","    cross_entropy_loss=nn.CrossEntropyLoss().cuda()\n","    # print(\"pred_for_29_timestamps shape\", pred_for_29_timestamps.shape)\n","    # print(\"targets_for_29_timestamps shape\", targets_for_29_timestamps.shape)\n","    inner_loss=0\n","    for i in range(max_len):\n","        inner_loss+=cross_entropy_loss(pred_for_29_timestamps[:,i,:].float(),targets_for_29_timestamps[:,i].long())\n","        \n","        # break\n","    # print(loss)\n","    return inner_loss/max_len    \n","\"\"\"\n","\n","def validation_step( batch,encoder,decoder,val_max_len,vocab_dict):\n","\n","    cross_entropy_loss=nn.CrossEntropyLoss().cuda()\n","    val_loss=0\n","\n","    imgs, captions = batch \n","    imgs = imgs.cuda()\n","    captions = captions.cuda()\n","    img_features = encoder(imgs)\n","    preds, alphas = decoder(img_features, captions ,val_max_len, flag=False)\n","    \n","\n","    targets = captions[:,:]\n","    preds_sentences=   generate_sentence_from_preds(preds,vocab_dict,val_max_len)     \n","    captions_sentences_list = generate_sentence_from_targets(targets ,vocab_dict, val_max_len)\n","    bleu_score_values = bleu_score( captions_sentences_list ,preds_sentences)\n","    bleu_score_val1 = bleu_score_values[0]\n","    bleu_score_val2 = bleu_score_values[1]\n","    bleu_score_val3 = bleu_score_values[2]\n","    bleu_score_val4 = bleu_score_values[3] \n","    meteor_score_val = meteor_score_calc( captions_sentences_list ,preds_sentences)\n","    \n","\n","    \"\"\"\n","    targets=targets.float()\n","    targets=targets.cuda()\n","    preds=torch.stack([preds,preds,preds,preds,preds],dim=1)\n","    preds=preds.float()\n","    \"\"\"\n","    targets = captions[:,0:1,:]\n","    targets=targets.reshape(targets.shape[0],targets.shape[2])\n","    targets = pack_padded_sequence(targets, [len(tar) - 1 for tar in targets], batch_first=True)[0]\n","    packed_preds = pack_padded_sequence(preds, [len(pred) - 1 for pred in preds], batch_first=True)[0]\n","\n","\n","    val_loss=cross_entropy_loss(packed_preds.float(), targets.long())\n","\n","\n","\n","\n","    # loss1=calc_loss(preds[:,0,:,:], targets[:,0,:],val_max_len)\n","    # loss2=calc_loss(preds[:,1,:,:], targets[:,1,:],val_max_len)\n","    # loss3=calc_loss(preds[:,2,:,:], targets[:,2,:],val_max_len)\n","    # loss4=calc_loss(preds[:,3,:,:], targets[:,3,:],val_max_len)\n","    # loss5=calc_loss(preds[:,4,:,:], targets[:,4,:],val_max_len)\n","    # val_loss = loss1+loss2+loss3+loss4+loss5\n","    # val_loss/=5\n","\n","    # acc = accuracy(out, labels)           # Calculate accuracy\n","    return ({'val_loss': val_loss.detach(), 'bleu_score_val1': bleu_score_val1,'bleu_score_val2': bleu_score_val2,'bleu_score_val3': bleu_score_val3,\\\n","            'bleu_score_val4': bleu_score_val4,'meteor_score_val':meteor_score_val},preds)\n","\n","def validation_epoch_end( outputs):\n","    batch_losses = [x['val_loss'] for x in outputs]\n","    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","\n","    batch_bleu_score1 = [x['bleu_score_val1'] for x in outputs]\n","    epoch_bleu_score1 = sum(batch_bleu_score1) / len(batch_bleu_score1)\n","\n","    batch_bleu_score2 = [x['bleu_score_val2'] for x in outputs]\n","    epoch_bleu_score2 = sum(batch_bleu_score2) / len(batch_bleu_score2)\n","\n","    batch_bleu_score3 = [x['bleu_score_val3'] for x in outputs]\n","    epoch_bleu_score3 = sum(batch_bleu_score3) / len(batch_bleu_score3)\n","\n","    batch_bleu_score4 = [x['bleu_score_val4'] for x in outputs]\n","    epoch_bleu_score4 = sum(batch_bleu_score4) / len(batch_bleu_score4)\n","\n","    batch_meteor_score = [x['meteor_score_val'] for x in outputs]\n","    epoch_meteor_score = sum(batch_meteor_score) / len(batch_meteor_score)\n","\n","    # batch_accs = [x['val_acc'] for x in outputs]\n","    # epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","    return {'val_loss': epoch_loss.item(), 'bleu_score_val1': epoch_bleu_score1,'bleu_score_val2': epoch_bleu_score2,'bleu_score_val3': epoch_bleu_score3,\\\n","            'bleu_score_val4': epoch_bleu_score4,'meteor_score_val': epoch_meteor_score}\n","\n","@torch.no_grad()     ## this signifies  dont calc computation graph on this func\n","def evaluate(val_loader,encoder,decoder,val_max_len,vocab_dict, flag=\"val\"):\n","    encoder.eval()\n","    decoder.eval()\n","\n","    dict_pred = [validation_step(batch,encoder,decoder,val_max_len,vocab_dict) for batch in val_loader]\n","\n","    outputs=[]    \n","    predicted_sentences=[]\n","    for i in range(len(dict_pred)):\n","        outputs.append(dict_pred[i][0])\n","        predicted_sentences.append(dict_pred[i][1])\n","\n","    # print(output)\n","    # print(pred)\n","    if (flag==\"val\"):\n","        return validation_epoch_end(outputs)\n","    elif(flag==\"test\"):\n","        return validation_epoch_end(outputs),predicted_sentences\n","\n","\n","def epoch_end(epoch, result):\n","  print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f},val_blue_score1: {:.4f},val_blue_score2: {:.4f},val_blue_score3: {:.4f},val_blue_score4: {:.4f},\\\n","  val_meteor_score: {:.4f}\".format(epoch, result['train_loss'], \\\n","        result['val_loss'],result['bleu_score_val1'],result['bleu_score_val2'],result['bleu_score_val3'],result['bleu_score_val4'],result['meteor_score_val']))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1423,"status":"ok","timestamp":1619162943459,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"ypBA7fPKtQGx"},"outputs":[],"source":["def generate_sentence_from_preds(preds,vocab_dict,max_len):\n","    # print(\"preds.shape\",preds.shape)   \n","    sentence_list=[]\n","    for i in range(preds.shape[0]):\n","        sentence=''\n","        for j in range(max_len):\n","            word_id=torch.argmax(preds[i][j]).item()\n","            # if j%500==0:\n","            #   print(word_id)\n","            org_word = list(vocab_dict.keys())[list(vocab_dict.values()).index(word_id)]\n","            sentence+= ' '+ org_word\n","        sentence_list.append(sentence) \n","    return sentence_list  \n","\n","def generate_sentence_from_targets(targets,vocab_dict,max_len):\n","    sentences_list=[]\n","    for i in range(targets.shape[0]):\n","        sentence_list=[]\n","        for caption in range(5):\n","          sentence=''\n","          for j in range(max_len):\n","            # word_id=torch.argmax(targets[i][caption][j]).item()\n","            word_id= targets[i][caption][j].item()\n","            # print(\"word_id\",word_id)\n","            org_word = list(vocab_dict.keys())[list(vocab_dict.values()).index(word_id)]\n","            # print(\"org_word\",org_word)\n","            sentence+= ' '+ org_word\n","\n","          sentence_list.append(sentence)\n","        sentences_list.append(sentence_list)\n","    return sentences_list\n","\n","\n","#requires editing\n","def bleu_score( captions_sentences_list ,preds_sentences):\n","    # print(captions_sentences_list)\n","    bleu_scores_list=[]\n","    generated_score1=0\n","    generated_score2=0\n","    generated_score3=0\n","    generated_score4=0\n","    for i in range(len(captions_sentences_list)):\n","        references=[]\n","        for j in range(5):\n","            word_tokens=captions_sentences_list[i][j].split(' ')\n","\n","            new_word_tokens_without_start_and_pad=[]    \n","            for word in word_tokens:\n","                if((word!='<start>') and (word!='<pad>')):\n","                    new_word_tokens_without_start_and_pad.append(word)\n","\n","            word_tokens=new_word_tokens_without_start_and_pad\n","            references.append(word_tokens)\n","\n","        candidate_sentence=    preds_sentences[i]\n","        candidates=candidate_sentence.split(' ')\n","\n","        new_candidates_tokens_without_start_and_pad=[]\n","        for word in candidates:\n","            if((word!='<start>') and (word!='<pad>')):\n","                new_candidates_tokens_without_start_and_pad.append(word)\n","        candidates=new_candidates_tokens_without_start_and_pad\n","\n","        # print(\"ref (out of 32 images) for every images 1st ref caption==>):\",references[0])\n","        # print(\"candidates (out of 32 predictions)  :\",candidates)\n","\n","        generated_score1 += sentence_bleu(references, candidates, weights=(1, 0, 0, 0),smoothing_function=SmoothingFunction().method4)\n","        generated_score2 += sentence_bleu(references, candidates, weights=(0, 1, 0, 0),smoothing_function=SmoothingFunction().method4)\n","        generated_score3 += sentence_bleu(references, candidates, weights=(0, 0, 1, 0),smoothing_function=SmoothingFunction().method4)\n","        generated_score4 += sentence_bleu(references, candidates, weights=(0, 0, 0, 1),smoothing_function=SmoothingFunction().method4)\n","    generated_score1 /=  len(captions_sentences_list)\n","    generated_score2 /=  len(captions_sentences_list)\n","    generated_score3 /=  len(captions_sentences_list)\n","    generated_score4 /=  len(captions_sentences_list)\n","    bleu_scores_list.append(generated_score1)\n","    bleu_scores_list.append(generated_score2)\n","    bleu_scores_list.append(generated_score3)\n","    bleu_scores_list.append(generated_score4)\n","    # return generated_score\n","    return bleu_scores_list\n","\n","\n","def pre_process_sentences(sentence):\n","    # print(\"sentence:\",sentence)\n","    modified_sentence=sentence.replace(\"<start> \",\"\")\n","    modified_sentence=modified_sentence.replace(\" <start>\",\"\")\n","    # modified_sentence=sentence.replace(\" <start> \",\" \")\n","\n","    modified_sentence=modified_sentence.replace(\"<pad> \",\"\")\n","    modified_sentence=modified_sentence.replace(\" <pad>\",\"\")\n","    # modified_sentence=sentence.replace(\" <pad> \",\" \")\n","\n","\n","    modified_sentence=modified_sentence.replace(\"<end> \",\"\")\n","    modified_sentence=modified_sentence.replace(\" <end>\",\"\")\n","    # modified_sentence=sentence.replace(\" <end> \",\" \")\n","\n","    # print(\"modified_sentence:\",modified_sentence)\n","    return modified_sentence\n","\n","\n","def meteor_score_calc(captions_sentences_list ,preds_sentences):\n","    generated_score=0\n","    for i in range(len(captions_sentences_list)):\n","        references=[]\n","        for j in range(5):\n","            # print(\"word_tokens :\",captions_sentences_list[i][j])\n","\n","            word_tokens=captions_sentences_list[i][j]\n","            word_tokens=pre_process_sentences(word_tokens)\n","            references.append(word_tokens)\n","\n","        candidate_sentence= preds_sentences[i]\n","        # print(\"candidate_sentence\",candidate_sentence)\n","        candidates=candidate_sentence\n","        candidates=pre_process_sentences(candidates)\n","        generated_score+= meteor_score(references, candidates)\n","\n","    generated_score/=  len(captions_sentences_list)\n","    return generated_score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1554,"status":"ok","timestamp":1619162959107,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"me3mc3bturOK"},"outputs":[],"source":["from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDR8YQkcyX_t"},"outputs":[],"source":["def train(epochs, encoder, decoder, data_loader,val_data_loader, word_dict,alpha_c,max_len,val_max_len,l_rate,filename,history_filename):\n","\n","    cross_entropy_loss=nn.CrossEntropyLoss().cuda()\n","    optimizer = torch.optim.Adam(decoder.parameters(),lr=l_rate)\n","\n","    loss=0\n","    history=[]\n","    result={}\n","    \n","    min_val_loss = 1e8\n","    best_epoch=0\n","    for epoch in range(epochs):\n","        encoder.eval()\n","        decoder.train()\n","\n","        train_losses=[]\n","\n","        blue_score_for_this_epoch1=0\n","        blue_score_for_this_epoch2=0\n","        blue_score_for_this_epoch3=0\n","        blue_score_for_this_epoch4=0\n","        meteor_score_for_this_epoch=0\n","        # print(len(data_loader))\n","\n","        cnt = 0\n","        for batch_idx, (imgs, captions) in enumerate(data_loader):\n","            # if (cnt>=1):\n","            #     break\n","            # cnt+=1    \n","            \n","            \n","            imgs = Variable(imgs).cuda()\n","            # print(\"imgs  ===>\",imgs.shape)            \n","            captions = Variable(captions).cuda()\n","            # captions_sentences_list=captions_sentences_list\n","            img_features = encoder(imgs)\n","            # print(\"encoder ka result image feature shape\",img_features.shape)\n","            optimizer.zero_grad()\n","            preds, alphas = decoder(img_features, captions ,max_len , flag=True)\n","            \n","            targets = captions[:,0:1,:]  \n","            # print(\"captions shape\",captions.shape)\n","            # print(\"targets shape\",targets.shape)\n","            # print(\"preds shape:\",preds.shape)\n","\n","            targets=targets.reshape(targets.shape[0],targets.shape[2])\n","            # print(\"targets 2 shape\",targets.shape)\n","            targets = pack_padded_sequence(targets, [len(tar) - 1 for tar in targets], batch_first=True)[0]\n","            # print(\"targets 3 shape\",targets.shape)\n","            # print(\" preds 1 shape :\", preds.shape)\n","            packed_preds = pack_padded_sequence(preds, [len(pred) - 1 for pred in preds], batch_first=True)[0]\n","            # print(\" packed_preds 1 shape :\", packed_preds.shape)\n","   \n","\n","            \n","            att_regularization = alpha_c * ((1 - alphas.sum(1))**2).mean()\n","            loss_train=cross_entropy_loss(packed_preds.float(), targets.long())\n","            loss_train+=att_regularization\n","            # print(\" hi\", LOSS_final.item())\n","\n","            # preds_sentences=   generate_sentence_from_preds(preds,vocab_dict,max_len)    \n","            # captions_sentences_list = generate_sentence_from_targets(targets ,vocab_dict, max_len)\n","\n","\n","            # targets=targets.float()\n","            # targets=targets.cuda()\n","            # preds=torch.stack([preds,preds,preds,preds,preds],dim=1)\n","            # preds=preds.float()\n","\n","            \n","            # loss1=calc_loss(preds[:,0,:,:], targets[:,0,:],max_len)\n","            # loss2=calc_loss(preds[:,1,:,:], targets[:,1,:],max_len)\n","            # loss3=calc_loss(preds[:,2,:,:], targets[:,2,:],max_len)\n","            # loss4=calc_loss(preds[:,3,:,:], targets[:,3,:],max_len)\n","            # loss5=calc_loss(preds[:,4,:,:], targets[:,4,:],max_len)\n","\n","            # loss = (loss1+loss2+loss3+loss4+loss5)/5\n","            # loss += att_regularization\n","            train_losses.append(loss_train)\n","\n","\n","            # print(\"epoch ==>\",e,\" and loss at i th batch===>\" ,loss)\n","            loss_train.backward()\n","            optimizer.step()\n","\n","\n","        no_of_batches=(len(data_loader)/batch_size)\n","        # blue_score_for_this_epoch1=blue_score_for_this_epoch1/ no_of_batches\n","        # blue_score_for_this_epoch2=blue_score_for_this_epoch1/ no_of_batches\n","        # blue_score_for_this_epoch3=blue_score_for_this_epoch1/ no_of_batches\n","        # blue_score_for_this_epoch4=blue_score_for_this_epoch1/ no_of_batches\n","        \n","        # meteor_score_for_this_epoch=meteor_score_for_this_epoch/ no_of_batches\n","\n","        # print(\"blue_score_for_this_epoch==> \",blue_score_for_this_epoch)\n","        # print(\"meteor_score_for_this_epoch==> \",meteor_score_for_this_epoch)\n","\n","        result = evaluate( val_dataset,encoder,decoder,val_max_len,vocab_dict)\n","        \n","        if result['val_loss']< min_val_loss:\n","          min_val_loss = result['val_loss']\n","        #   save_model(encoder,filename+'_encoder')\n","        #   save_model(decoder,filename+'_decoder')\n","          best_epoch=epoch\n","\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        # print(\"loss at epoch ==>\",epoch ,\" == \",result['train_loss'])\n","\n","        # result['bleu_train_score1']=blue_score_for_this_epoch1\n","        # result['bleu_train_score2']=blue_score_for_this_epoch2\n","        # result['bleu_train_score3']=blue_score_for_this_epoch3\n","        # result['bleu_train_score4']=blue_score_for_this_epoch4\n","        # result['meteor_train_score']=meteor_score_for_this_epoch\n","        epoch_end(epoch , result)  #for printing everything\n","        history.append(result)\n","        # joblib.dump(history,'/content/drive/MyDrive/Deep Learning/A4/models/'+history_filename)\n","\n","    return history,encoder,decoder,best_epoch "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2409572,"status":"ok","timestamp":1618766649093,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"GvDsObghyely","outputId":"dc584ed5-7206-449e-a607-a27a31a173fd"},"outputs":[],"source":["from torch.autograd import Variable\n","encoder = Encoder().cuda()\n","print(\"length of vocab\",len(vocab_dict))\n","# attention = Attention(512).cuda()\n","decoder = Decoder(len(vocab_dict),512).cuda()\n","history,encoder,decoder,best_epoch = train(20,encoder,decoder,train_dataset,val_dataset,vocab_dict,0.3,max_length,max_length_val,l_rate=0.0001,filename='run1',history_filename='run1')\n","# history1,encoder,decoder = train(30,encoder,decoder,train_dataset,val_dataset,vocab_dict,0.1,max_length,max_length_val,l_rate=0.0001,filename='run2')\n","# history2,encoder,decoder = train(30,encoder,decoder,train_dataset,val_dataset,vocab_dict,0.1,max_length,max_length_val,l_rate=0.0001,filename='run3')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZY3EwVfmA0Jq"},"outputs":[],"source":["# torch.save(encoder.state_dict(),'/content/drive/My Drive/Deep Learning/A4/models/'+'20th_epoch_encoder'+'_cp.pth')\n","# torch.save(decoder.state_dict(),'/content/drive/My Drive/Deep Learning/A4/models/'+'20th_epoch_decoder'+'_cp.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DzNuPe8XLpG"},"outputs":[],"source":["'''\n","file_path_enc = '/content/drive/MyDrive/Deep Learning/A4/models/run1_encoder_cp.pth'\n","file_path_dec = '/content/drive/MyDrive/Deep Learning/A4/models/run1_decoder_cp.pth'\n","\n","vocab_dict = joblib.load('/content/drive/MyDrive/Deep Learning/A4/models/vocab_dict')\n","\n","encoder = Encoder().cuda()\n","checkpoint_enc = torch.load(file_path_enc)\n","encoder.load_state_dict(checkpoint_enc)\n","\n","decoder = Decoder(len(vocab_dict),512).cuda()\n","checkpoint_dec = torch.load(file_path_dec)\n","decoder.load_state_dict(checkpoint_dec)\n","\n","history1,encoder,decoder = train(5,encoder,decoder,train_dataset,val_dataset,vocab_dict,0.3,max_length,max_length_val,l_rate=0.001,filename='run2',history_filename='run2')\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCUDQCMRxtPt"},"outputs":[],"source":["\"\"\"\n","file_path_enc = '/content/drive/MyDrive/Deep Learning/A4/models/run1_encoder_cp.pth'\n","file_path_dec = '/content/drive/MyDrive/Deep Learning/A4/models/run1_decoder_cp.pth'\n","\n","vocab_dict = joblib.load('/content/drive/MyDrive/Deep Learning/A4/models/vocab_dict')\n","\n","enc = Encoder().cuda()\n","checkpoint_enc = torch.load(file_path_enc)\n","enc.load_state_dict(checkpoint_enc)\n","\n","dec = Decoder(len(vocab_dict),512).cuda()\n","checkpoint_dec = torch.load(file_path_dec)\n","dec.load_state_dict(checkpoint_dec)\n","\n","history2,encoder,decoder = train(100,enc,dec,train_dataset,val_dataset,vocab_dict,0.0001,max_length,max_length_val,l_rate=0.0001,filename='run2')\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":1116,"status":"ok","timestamp":1618766817402,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"3sPL7j_5y6lY","outputId":"354459f0-1032-4dd2-e846-6238e3693d8b"},"outputs":[],"source":["def helper_plot(history):\n","  val_loss=[]\n","  # val_bleu_score=[]\n","  # val_meteor_score=[]\n","  train_loss=[]\n","  val_bleu_score_1=[]\n","  val_bleu_score_2=[]\n","  val_bleu_score_3=[]\n","  val_bleu_score_4=[]\n","  val_meteor_score=[]\n","  for i in range(len(history)):\n","    val_loss.append(history[i]['val_loss'])\n","    # val_bleu_score.append(history[i]['bleu_score_val'])\n","    # val_meteor_score.append(history[i]['meteor_score_val'])\n","    train_loss.append(history[i]['train_loss'])\n","    # train_bleu_score.append(history[i]['bleu_train_score'])\n","    # train_meteor_score.append(history[i]['meteor_train_score'])\n","    val_bleu_score_1.append(history[i]['bleu_score_val1'])\n","    val_bleu_score_2.append(history[i]['bleu_score_val2'])\n","    val_bleu_score_3.append(history[i]['bleu_score_val3'])\n","    val_bleu_score_4.append(history[i]['bleu_score_val4'])\n","\n","    val_meteor_score.append(history[i]['meteor_score_val'])\n","\n","\n","\n","  # return val_loss, train_loss, train_bleu_score, train_meteor_score,val_bleu_score, val_meteor_score\n","  return val_loss, train_loss,val_bleu_score_1,val_bleu_score_2,val_bleu_score_3,val_bleu_score_4,val_meteor_score\n","\n","def loss_plot(file,train_loss,val_loss):\n","    x_axis = np.arange(1,21)\n","    plt.plot(x_axis,val_loss, color=\"red\", label=\"validation loss\")\n","    plt.plot(x_axis,train_loss, color=\"blue\",  label=\"train loss\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"loss\")\n","    plt.title('loss plot')\n","    # plt.savefig('/content/drive/MyDrive/Deep Learning/A4/plots/'+file)\n","    plt.legend()\n","\n","\n","def bleu_plot(file,val_bleu_score_1,val_bleu_score_2,val_bleu_score_3,val_bleu_score_4):\n","    x_axis = np.arange(1,21)\n","    plt.plot(x_axis,val_bleu_score_1, color=\"red\", label=\"val_bleu_score_1\")\n","    plt.plot(x_axis,val_bleu_score_2, color=\"blue\", label=\"val_bleu_score_2\")\n","    plt.plot(x_axis,val_bleu_score_3, color=\"green\", label=\"val_bleu_score_3\")\n","    plt.plot(x_axis,val_bleu_score_4, color=\"black\", label=\"val_bleu_score_4\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"blue scores\")\n","    plt.title('bleu plot')\n","    # plt.savefig('/content/drive/MyDrive/Deep Learning/A4/plots/'+file)\n","    plt.legend()\n","\n","\n","def meteor_plot(file,val_meteor_score):\n","    x_axis = np.arange(1,21)\n","    plt.plot(x_axis,val_meteor_score, color=\"red\", label=\"val_meteor_score\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"val_meteor_score\")\n","    plt.title('meteor plot')\n","    # plt.savefig('/content/drive/MyDrive/Deep Learning/A4/plots/'+file)\n","    plt.legend()    \n","\n","history = joblib.load('/content/drive/MyDrive/Deep Learning/A4/models/run1')\n","val_loss, train_loss,val_bleu_score_1,val_bleu_score_2,val_bleu_score_3,val_bleu_score_4,val_meteor_score= helper_plot(history)\n","loss_plot('plot.jpg',train_loss,val_loss)  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":1189,"status":"ok","timestamp":1618766848260,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"wd8wrYNuyHdA","outputId":"b9043e34-dd89-432e-f19b-9eb52ccb0062"},"outputs":[],"source":["bleu_plot('bleu.jpg',val_bleu_score_1,val_bleu_score_2,val_bleu_score_3,val_bleu_score_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":1024,"status":"ok","timestamp":1618766853156,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"nDLNNy3pyLyJ","outputId":"a056f9ab-4e5b-4838-dbcf-c22a832a55db"},"outputs":[],"source":["meteor_plot('meteor.jpg',val_meteor_score) "]},{"cell_type":"markdown","metadata":{"id":"C7qn9lOfHZ5h"},"source":["Show attention weights for each word in 5 images."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4791,"status":"ok","timestamp":1619163551243,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"QoBVckJ9U9fK","outputId":"6d29698b-ffef-4c50-ec9f-9abb22108db7"},"outputs":[],"source":["import math\n","\n","import skimage\n","import skimage.transform\n","\n","file_path_enc = '/content/drive/MyDrive/Deep Learning/A4/models/20th_epoch_encoder_cp.pth'\n","file_path_dec = '/content/drive/MyDrive/Deep Learning/A4/models/20th_epoch_decoder_cp.pth'\n","vocab_dict = joblib.load('/content/drive/MyDrive/Deep Learning/A4/models/vocab_dict')\n","\n","enc = Encoder().cuda()\n","checkpoint_enc = torch.load(file_path_enc)\n","enc.load_state_dict(checkpoint_enc)\n","dec = Decoder(len(vocab_dict),512).cuda()\n","checkpoint_dec = torch.load(file_path_dec)\n","dec.load_state_dict(checkpoint_dec)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14390,"status":"ok","timestamp":1618768071953,"user":{"displayName":"sushil chandra","photoUrl":"","userId":"17856687879375372229"},"user_tz":-330},"id":"SBwtcbOvU-jV","outputId":"4c1f2836-6e33-450f-dea4-f667b75ce81b"},"outputs":[],"source":["# enc = encoder\n","# dec = decoder\n","\n","\n","enc.eval()\n","dec.eval()\n","\n","cnt=0\n","for batch_idx, (imgs, captions) in enumerate(train_dataset):\n","  if cnt >0:\n","    break\n","  cnt+=1\n","  imgs = imgs.cuda()\n","  captions = captions.cuda()\n","  # print(captions.shape)\n","  img_features = enc(imgs)\n","  preds, alphas = dec(img_features, captions ,max_length)\n","  # print(preds.shape)\n","  # print(max_length)\n","  # print(captions.shape)\n","  # print(img_features.shape)\n","  # print(alphas.shape)\n","  alphas = alphas.reshape(alphas.shape[0],alphas.shape[1],14,14)\n","  # print(alphas.shape)\n","\n","  for images in range(5):\n","\n","    corresponding_img=imgs[images]  \n","    preds_sentence=  generate_sentence_from_preds(preds[images:images+1],vocab_dict,max_length) \n","    print(\"predicted caption\",preds_sentence)    \n","    captions_sentences_list = generate_sentence_from_targets(captions[images:images+1],vocab_dict, max_length)\n","    print(\"original captions\",captions_sentences_list)\n","  \n","    alpha_list = []\n","    for word in range(captions[images].shape[1]):\n","      alpha = alphas[images][word].detach().cpu().numpy()\n","      alpha = alpha*255\n","      alpha = alpha.astype('uint8')\n","\n","\n","      alpha_list.append(alpha)    \n","    #   cv2_imshow(alpha)\n","    \n","    w=10\n","    h=10\n","    fig=plt.figure(figsize=(30, 30))\n","    columns = math.ceil(math.sqrt(captions[images].shape[1]))\n","    rows = math.ceil(math.sqrt(captions[images].shape[1]))\n","    for i in range(1, captions[images].shape[1]+1):\n","\n","        corresponding_img=imgs[images]  \n","        img = alpha_list[i-1]\n","        \n","\n","        # print(i)\n","        preds_sentence_words=preds_sentence[0].split(' ')\n","        # print('preds_sentence_words:',preds_sentence_words)\n","        # print(len(preds_sentence_words))\n","        # print(preds_sentence_words[i])\n","\n","        if (preds_sentence_words[i]=='<end>'):\n","            \n","            corresponding_img=corresponding_img.permute(1,2,0)\n","            corresponding_img=corresponding_img.detach().cpu().numpy()\n","            corresponding_img=corresponding_img*255\n","            corresponding_img=corresponding_img.astype('uint8')\n","            corresponding_img=cv2.resize(corresponding_img,(224,224))\n","            cv2_imshow(corresponding_img)\n","            break\n","        fig.add_subplot(rows, columns, i)\n","        plt.gca().set_title(preds_sentence_words[i])\n","        alpha_img = skimage.transform.pyramid_expand(img, upscale=16, sigma=2)\n","\n","\n","        corresponding_img=corresponding_img.permute(1,2,0)\n","        corresponding_img=corresponding_img.detach().cpu().numpy()\n","        corresponding_img=corresponding_img*255\n","        corresponding_img=corresponding_img.astype('uint8')\n","        corresponding_img=cv2.resize(corresponding_img,(224,224))\n","        # corresponding_img=corresponding_img.astype('float')\n","        # cv2_imshow(corresponding_img)\n","        # print(corresponding_img.shape)\n","        # # alpha_img*=255\n","        # # alpha_img=alpha_img.astype('uint8')\n","        # # cv2_imshow(alpha_img)\n","        alpha_img= (alpha_img-alpha_img.min() ) /( alpha_img.max()-alpha_img.min()  )\n","        alpha_img=alpha_img*255\n","        alpha_img=alpha_img.astype('uint8')\n","\n","        # print(alpha_img)\n","        # cv2_imshow(alpha_img)\n","\n","        alpha_img=np.dstack((alpha_img,alpha_img,alpha_img))\n","        Attention_images = cv2.addWeighted(corresponding_img, 0.4, alpha_img, 0.8, 0)\n","\n","        plt.imshow(Attention_images)\n","        plt.axis('off')\n","    # fig.savefig('/content/drive/MyDrive/Deep Learning/A4/visualise_attention_weights/attention_plot'+str(images)+'.png')\n","    plt.show()      "]},{"cell_type":"markdown","metadata":{"id":"Gn2AYu-ywdGv"},"source":["Evaluation on Test Set "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65801,"status":"ok","timestamp":1619163952756,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"7bd_iCa6VIlE","outputId":"8813fc80-a8d2-4351-95f4-9cbe75415917"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","def test():\n","  file_path_enc = '/content/drive/MyDrive/Deep Learning/A4/models/run1_encoder_cp.pth'\n","  file_path_dec = '/content/drive/MyDrive/Deep Learning/A4/models/run1_decoder_cp.pth'\n","\n","  vocab_dict = joblib.load('/content/drive/MyDrive/Deep Learning/A4/models/vocab_dict')\n","\n","  enc = Encoder().cuda()\n","  checkpoint_enc = torch.load(file_path_enc)\n","  enc.load_state_dict(checkpoint_enc)\n","  dec = Decoder(len(vocab_dict),512).cuda()\n","  checkpoint_dec = torch.load(file_path_dec)\n","  dec.load_state_dict(checkpoint_dec)\n","\n","  test_data_images_path= '/content/drive/MyDrive/Deep Learning/A4/Data/Test/Images'\n","  test_data_images_captions= joblib.load('/content/drive/MyDrive/Deep Learning/A4/Data/Test/test_captions.pkl')\n","  # test_data_images_captions = {k: test_data_images_captions[k] for k in list(test_data_images_captions)[:100]}\n","\n","\n","\n","  test_caption_in_no_tensor,test_max_len= pre_process_captions(test_data_images_captions,vocab_dict)\n","  x_test  ,y_test=   pre_process_and_load(test_data_images_path,test_data_images_captions)  \n","  x_test_tensor= torch.stack(x_test)\n","  y_test=y_test\n","  test_ds = list(zip(x_test_tensor,test_caption_in_no_tensor))\n","  batch_size = 32\n","  test_dataset = DataLoader(test_ds,batch_size)\n","  test_dataset = DeviceDataLoader(test_dataset,torch.device('cuda'))\n","  \n","  result, predicted_sentences = evaluate(test_dataset,enc,dec,test_max_len,vocab_dict, flag=\"test\")\n","\n","  print(\"val_loss: {:.4f}, val_blue_score1: {:.4f},val_blue_score2: {:.4f},val_blue_score3: {:.4f},val_blue_score4: {:.4f},\\\n","   val_meteor_score: {:.4f}\".format(\\\n","      result['val_loss'],result['bleu_score_val1'],result['bleu_score_val2'],result['bleu_score_val3'],result['bleu_score_val4'],result['meteor_score_val']))\n","  \n","  # print(len(predicted_sentences))\n","  # print(len(predicted_sentences[0]))\n","  # print(len(predicted_sentences[0][0]))\n","  # print(predicted_sentences[0][0])\n","#   print(np.array(predicted_sentences).shape)\n","\n","  sentence_list=  generate_sentence_from_preds(predicted_sentences[0],vocab_dict,test_max_len) \n","  print(sentence_list)\n","  return test_dataset,test_max_len\n","\n","  \n","test_dataset,test_max_len=test()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":37933,"status":"ok","timestamp":1619164618837,"user":{"displayName":"Soumam Banerjee","photoUrl":"","userId":"04672628396352490704"},"user_tz":-330},"id":"bq9afE9QqWxy","outputId":"b9c62b75-40b0-499a-a640-8565a5bb43f4"},"outputs":[],"source":["\n","\n","enc.eval()\n","dec.eval()\n","\n","cnt=0\n","for batch_idx, (imgs, captions) in enumerate(test_dataset):\n","  if cnt >0:\n","    break\n","  cnt+=1\n","  imgs = imgs.cuda()\n","  captions = captions.cuda()\n","  # print(captions.shape)\n","  img_features = enc(imgs)\n","  print(img_features.shape)\n","  print(captions.shape)\n","  print(max_length)\n","  preds, alphas = dec(img_features, captions ,test_max_len)\n","  # print(preds.shape)\n","  # print(max_length)\n","  # print(captions.shape)\n","  # print(img_features.shape)\n","  # print(alphas.shape)\n","  alphas = alphas.reshape(alphas.shape[0],alphas.shape[1],14,14)\n","  # print(alphas.shape)\n","\n","  for images in range(20):\n","\n","    corresponding_img=imgs[images]  \n","    preds_sentence=  generate_sentence_from_preds(preds[images:images+1],vocab_dict,test_max_len) \n","    print(\"predicted caption\",preds_sentence)    \n","    captions_sentences_list = generate_sentence_from_targets(captions[images:images+1],vocab_dict, test_max_len)\n","    print(\"original captions\",captions_sentences_list)\n","  \n","    alpha_list = []\n","    for word in range(captions[images].shape[1]):\n","      alpha = alphas[images][word].detach().cpu().numpy()\n","      alpha = alpha*255\n","      alpha = alpha.astype('uint8')\n","\n","\n","      alpha_list.append(alpha)    \n","    #   cv2_imshow(alpha)\n","    \n","    w=10\n","    h=10\n","    fig=plt.figure(figsize=(30, 30))\n","    columns = math.ceil(math.sqrt(captions[images].shape[1]))\n","    rows = math.ceil(math.sqrt(captions[images].shape[1]))\n","    for i in range(1, captions[images].shape[1]+1):\n","\n","        corresponding_img=imgs[images]  \n","        img = alpha_list[i-1]\n","        \n","\n","        # print(i)\n","        preds_sentence_words=preds_sentence[0].split(' ')\n","        # print('preds_sentence_words:',preds_sentence_words)\n","        # print(len(preds_sentence_words))\n","        # print(preds_sentence_words[i])\n","\n","        if (preds_sentence_words[i]=='<end>'):\n","            \n","            corresponding_img=corresponding_img.permute(1,2,0)\n","            corresponding_img=corresponding_img.detach().cpu().numpy()\n","            corresponding_img=corresponding_img*255\n","            corresponding_img=corresponding_img.astype('uint8')\n","            corresponding_img=cv2.resize(corresponding_img,(224,224))\n","            cv2_imshow(corresponding_img)\n","            break\n","        fig.add_subplot(rows, columns, i)\n","        plt.gca().set_title(preds_sentence_words[i])\n","        alpha_img = skimage.transform.pyramid_expand(img, upscale=16, sigma=2)\n","\n","\n","        corresponding_img=corresponding_img.permute(1,2,0)\n","        corresponding_img=corresponding_img.detach().cpu().numpy()\n","        corresponding_img=corresponding_img*255\n","        corresponding_img=corresponding_img.astype('uint8')\n","        corresponding_img=cv2.resize(corresponding_img,(224,224))\n","        # corresponding_img=corresponding_img.astype('float')\n","        # cv2_imshow(corresponding_img)\n","        # print(corresponding_img.shape)\n","        # # alpha_img*=255\n","        # # alpha_img=alpha_img.astype('uint8')\n","        # # cv2_imshow(alpha_img)\n","        alpha_img= (alpha_img-alpha_img.min() ) /( alpha_img.max()-alpha_img.min()  )\n","        alpha_img=alpha_img*255\n","        alpha_img=alpha_img.astype('uint8')\n","\n","        # print(alpha_img)\n","        # cv2_imshow(alpha_img)\n","\n","        alpha_img=np.dstack((alpha_img,alpha_img,alpha_img))\n","        Attention_images = cv2.addWeighted(corresponding_img, 0.4, alpha_img, 0.8, 0)\n","\n","        plt.imshow(Attention_images)\n","        plt.axis('off')\n","    # fig.savefig('/content/drive/MyDrive/Deep Learning/A4/visualise_attention_weights/attention_plot'+str(images)+'.png')\n","    plt.show()  "]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"final_DL_Ass4_Ques1_final_run.ipynb","provenance":[{"file_id":"1E2irY_l3GZ4pgXk5kPpOVXTjs2EgU_bb","timestamp":1618753389599}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
